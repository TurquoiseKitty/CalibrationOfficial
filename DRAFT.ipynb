{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5452087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnost the boston dataset\n",
    "import os\n",
    "from src.models import vanilla_predNet, MC_dropnet, Deep_Ensemble\n",
    "from src.losses import mse_loss, rmse_loss, mean_std_norm_loss, mean_std_forEnsemble, BeyondPinball_muSigma, MMD_Loss, MACE_Loss, MACE_muSigma\n",
    "import torch\n",
    "from src.GPmodels import oneLayer_DeepGP\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import operator\n",
    "import yaml\n",
    "from Experiments.EXP1.trainer import trainer\n",
    "from data_utils import seed_all, splitter, common_processor_UCI, get_uci_data\n",
    "\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "dataset_name = \"boston\"\n",
    "dataname = \"boston\"\n",
    "dataset_path = \"Experiments/EXP1/UCI_datasets\"\n",
    "\n",
    "model_callByName = {\n",
    "    \"GPmodel\": oneLayer_DeepGP,\n",
    "    \"HNN\": MC_dropnet,\n",
    "    \"MC_drop\": MC_dropnet,\n",
    "    \"DeepEnsemble\": Deep_Ensemble,\n",
    "    \"HNN_BeyondPinball\": MC_dropnet,\n",
    "    \"vanillaPred\": vanilla_predNet,\n",
    "\n",
    "    \"HNN_MMD\": MC_dropnet,\n",
    "    \"vanillaMSQR\": vanilla_predNet,\n",
    "    \"vanillaKernel\": vanilla_predNet\n",
    "}\n",
    "\n",
    "loss_callByName = {\n",
    "    \"mse_loss\": mse_loss, \n",
    "    \"rmse_loss\": rmse_loss, \n",
    "    \"mean_std_norm_loss\": mean_std_norm_loss, \n",
    "    \"mean_std_forEnsemble\": mean_std_forEnsemble, \n",
    "    \"BeyondPinball_muSigma\": BeyondPinball_muSigma,\n",
    "    \"MMD_Loss\": MMD_Loss,\n",
    "    \"MACE_Loss\": MACE_Loss,\n",
    "    \"MACE_muSigma\": MACE_muSigma\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x, y = get_uci_data(data_name= dataset_name, dir_name= dataset_path)\n",
    "\n",
    "train_X, test_X, recal_X, train_Y, test_Y, recal_Y = common_processor_UCI(x, y, recal_percent= 0.5, seed = SEED)\n",
    "\n",
    "train_X = torch.Tensor(train_X)\n",
    "train_Y = torch.Tensor(train_Y).to(torch.device(\"cuda\"))\n",
    "\n",
    "\n",
    "\n",
    "with open(\"Experiments/EXP1/config_bin/vanillaPred_on_\"+dataname+\"_config.yml\", 'r') as file:\n",
    "    base_configs = yaml.safe_load(file)\n",
    "\n",
    "base_misc_info = base_configs[\"misc_info\"]\n",
    "base_train_config= base_configs[\"training_config\"]\n",
    "\n",
    "\n",
    "base_model = model_callByName[base_misc_info[\"model_init\"]](**base_misc_info[\"model_config\"])\n",
    "\n",
    "\n",
    "trainer(\n",
    "    seed = SEED,\n",
    "    raw_train_X = train_X,\n",
    "    raw_train_Y = train_Y,\n",
    "    model = base_model,\n",
    "    training_config = base_train_config,\n",
    "    harvestor = None,          \n",
    "    misc_info = base_misc_info,\n",
    "    diff_trainingset = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"rmse_loss\": rmse_loss, \n",
    "\"mean_std_norm_loss\": mean_std_norm_loss, \n",
    "    \n",
    "    \n",
    "\"MACE_muSigma\": MACE_muSigma,\n",
    "\n",
    "\"AGCE_muSigma\": AGCE_muSigma,\n",
    "\n",
    "\"CheckScore_muSigma\": avg_pinball_muSigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e9864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "dic = {\n",
    "    \"hh\":1,\n",
    "    \"oo\":2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3019a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dic.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c23419",
   "metadata": {},
   "outputs": [],
   "source": [
    "recal_X = torch.Tensor(recal_X)\n",
    "            recal_Y = torch.Tensor(recal_Y).to(torch.device(base_misc_info[\"model_config\"][\"device\"]))\n",
    "\n",
    "            # we need to get those val_x and val_y\n",
    "            split_percet = base_misc_info[\"val_percentage\"]\n",
    "    \n",
    "            N_val = int(split_percet*len(train_Y))\n",
    "\n",
    "            train_idx, val_idx = splitter(len(train_Y)-N_val, N_val, seed = SEED)\n",
    "\n",
    "            val_X, val_Y = train_X[val_idx], train_Y[val_idx]\n",
    "\n",
    "            recal_mean = base_model(recal_X).view(-1)\n",
    "            val_mean = base_model(val_X).view(-1)\n",
    "            \n",
    "            assert \"wid\" in to_search\n",
    "\n",
    "            for wid in to_search[\"wid\"]:\n",
    "\n",
    "                eps_diffQuants = kernel_estimator(\n",
    "                    test_Z = val_X.cuda(),\n",
    "                    recal_Z = recal_X.cuda(),\n",
    "                    recal_epsilon = torch.Tensor(recal_Y - recal_mean).cuda(),\n",
    "                    quants = np.linspace(0.01,0.99,100),\n",
    "                    wid= wid\n",
    "                )\n",
    "\n",
    "                y_diffQuants = eps_diffQuants + val_mean.view(1,-1).repeat(len(eps_diffQuants),1)\n",
    "                MACE_error = MACE_Loss(y_diffQuants,val_Y,q_list = np.linspace(0.01,0.99,100)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_misc_info:\n",
    "  input_x_shape:\n",
    "  - 8611\n",
    "  - 4\n",
    "  input_y_shape:\n",
    "  - 8611\n",
    "  model_config:\n",
    "    device: cuda\n",
    "    drop_rate: 0.0\n",
    "    hidden_layers:\n",
    "    - 10\n",
    "    - 5\n",
    "    n_input: 4\n",
    "    n_output: 2\n",
    "  model_init: HNN_MMD\n",
    "  save_path_and_name: null\n",
    "  val_percentage: 0.1\n",
    "aux_train_config:\n",
    "  Decay: 0.0001\n",
    "  LR: 0.001\n",
    "  N_Epoch: 200\n",
    "  backdoor: null\n",
    "  bat_size: 128\n",
    "  early_stopping: true\n",
    "  monitor_name: MMD\n",
    "  patience: 20\n",
    "  train_loss: MMD_Loss\n",
    "  val_loss_criterias:\n",
    "    MACE: MACE_muSigma\n",
    "    MMD: MMD_Loss\n",
    "    nll: mean_std_norm_loss\n",
    "    rmse: rmse_loss\n",
    "  validate_times: 20\n",
    "  verbose: false\n",
    "base_misc_info:\n",
    "  input_x_shape:\n",
    "  - 8611\n",
    "  - 4\n",
    "  input_y_shape:\n",
    "  - 8611\n",
    "  model_config:\n",
    "    device: cuda\n",
    "    drop_rate: 0.0\n",
    "    hidden_layers:\n",
    "    - 10\n",
    "    - 5\n",
    "    n_input: 4\n",
    "    n_output: 2\n",
    "  model_init: HNN_MMD\n",
    "  save_path_and_name: null\n",
    "  val_percentage: 0.1\n",
    "base_train_config:\n",
    "  Decay: 0.0001\n",
    "  LR: 0.005\n",
    "  N_Epoch: 200\n",
    "  backdoor: null\n",
    "  bat_size: 64\n",
    "  early_stopping: true\n",
    "  monitor_name: nll\n",
    "  patience: 20\n",
    "  train_loss: mean_std_norm_loss\n",
    "  val_loss_criterias:\n",
    "    MACE: MACE_muSigma\n",
    "    nll: mean_std_norm_loss\n",
    "    rmse: rmse_loss\n",
    "  validate_times: 20\n",
    "  verbose: false\n",
    "harvestor:\n",
    "  early_stopped: false\n",
    "  early_stopping_epoch: 0\n",
    "  monitor_name: MACE\n",
    "  monitor_vals: []\n",
    "  training_losses: []\n",
    "  val_MACE: []\n",
    "  val_MMD: []\n",
    "  val_nll: []\n",
    "  val_rmse: []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        if model_name == \"HNN_MMD\": \n",
    "            # base model will be reused\n",
    "\n",
    "            aux_misc_info = copy.deepcopy(base_misc_info)\n",
    "            aux_train_config = copy.deepcopy(base_train_config)\n",
    "\n",
    "            aux_train_config[\"train_loss\"] = \"MMD_Loss\"\n",
    "\n",
    "            aux_train_config[\"val_loss_criterias\"] = {\n",
    "                \"MMD\": \"MMD_Loss\",\n",
    "                \"MACE\": \"MACE_muSigma\",\n",
    "                \"nll\": \"mean_std_norm_loss\",\n",
    "                \"rmse\": \"rmse_loss\"\n",
    "            }\n",
    "            aux_train_config[\"monitor_name\"] = \"MMD\"\n",
    "\n",
    "            harvestor = {\n",
    "                \"early_stopped\": False,\n",
    "                \"early_stopping_epoch\": 0,\n",
    "                \"monitor_name\": \"MACE\",\n",
    "                \"monitor_vals\": [],\n",
    "                \"training_losses\": [],\n",
    "                \"val_MMD\": [],\n",
    "                \"val_MACE\": [],\n",
    "                \"val_nll\": [],\n",
    "                \"val_rmse\": []\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "            assert \"LR\" in to_search.keys() and \"bat_size\" in to_search.keys()\n",
    "\n",
    "            for LR in to_search[\"LR\"]:\n",
    "                for bat_size in to_search[\"bat_size\"]:\n",
    "                    aux_train_config[\"LR\"] = LR\n",
    "                    aux_train_config[\"bat_size\"] = bat_size\n",
    "\n",
    "                    empty_harvestor(harvestor)\n",
    "\n",
    "                    model_reuse = copy.deepcopy(base_model)\n",
    "\n",
    "                    trainer(\n",
    "                        seed = SEED,\n",
    "                        raw_train_X = train_X,\n",
    "                        raw_train_Y = train_Y,\n",
    "                        model = model_reuse,\n",
    "                        training_config = aux_train_config,\n",
    "                        harvestor = harvestor,          \n",
    "                        misc_info = aux_misc_info\n",
    "                    )\n",
    "\n",
    "                \n",
    "                    sub_summarizer[(LR, bat_size)] = np.mean(harvestor[\"monitor_vals\"][-3:])\n",
    "                    aid_summarizer[(LR, bat_size)] = {}\n",
    "\n",
    "                    for key in aux_train_config[\"val_loss_criterias\"].keys():\n",
    "                        aid_summarizer[(LR, bat_size)][\"val_\"+key] = np.mean(harvestor[\"val_\"+key][-3:])\n",
    "\n",
    "\n",
    "            para_got = min(sub_summarizer.items(), key=operator.itemgetter(1))[0]\n",
    "            summarizer.append(para_got)\n",
    "            support_summ[para_got] = aid_summarizer[para_got]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
